{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfcf532",
   "metadata": {},
   "source": [
    "Rhasspy is a magnificent voice management software. It's open-source, multi-platform and allows API to:\n",
    "\n",
    "* Manage mic and speakers\n",
    "* Runs speech recognition that is based on predefined sentences\n",
    "* Has a text-to-speech features, although it's less impressive\n",
    "* Manages wake-up-word\n",
    "\n",
    "In other words, Rhasspy is a solid foundation for our home assistant.\n",
    "\n",
    "Simplest way to install it is Docker. You need to have Docker on your local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4e77e2-e5c0-4a90-aa1c-c6c181203724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaia.avatar.dub.languages.en import RhasspyAPI\n",
    "\n",
    "RhasspyAPI.warmup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0d82f",
   "metadata": {},
   "source": [
    "This will download everything that is needed.\n",
    "\n",
    "You only need to do it once, as Rhasspy adds itself to the docker startup and starts atomatically when the system boots (or, in Windows, when Docker starts).\n",
    "\n",
    "The command _will not_ connect Rhasspy to your microphone or speakers, as we are not intended to use this functionality right now.\n",
    "\n",
    "You can now open Rhasspy and see what's there. You won't need to configure it manually, as in the following cells we'll configure Rhasspy via api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c36bcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://127.0.0.1:12101\" target=\"_blank\">Open Rhasspy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "ADDRESS = '127.0.0.1:12101'\n",
    "\n",
    "HTML(f'<a href=\"http://{ADDRESS}\" target=\"_blank\">Open Rhasspy</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28138a15-0489-4ebc-a1b5-3af6b62d7bfd",
   "metadata": {},
   "source": [
    "Open the link, set \"Kaldi\" for \"Speech-to-text\" and \"Fsticuffs\" for \"Intent recognition\". Save and restart, then click \"Download\" on the top of the page. This will configure Rhasspy for the functionality we need.\n",
    "\n",
    "It is sure possible to achieve programmatically via API, but I failed to do it fast and decided not to dive into this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85d4c9-cf01-4a26-ba39-6cd674d429ae",
   "metadata": {},
   "source": [
    "Now let's try Rhasspy in action. First, let's reproduce steps from the previous notebooks and create and audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba643b81-20ed-4eec-8133-2e5149094ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed9411248cd4133b33e19b472479080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Audio(value=b'RIFFD\\x18\\x02\\x00WAVEfmt \\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00\"V\\x00\\x00D\\xac\\x00\\x00\\x02\\x00\\x10\\x00â€¦"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaia.brainbox import BrainBoxTask, BrainBoxTaskPack, DownloadingPostprocessor, BrainBox\n",
    "from kaia.infra import FileIO\n",
    "from ipywidgets import Audio\n",
    "from kaia.avatar.server.dubbing_service import BrainBoxDubbingService\n",
    "from kaia.brainbox import BrainBox\n",
    "from kaia.avatar.dub.languages.en import *\n",
    "\n",
    "def task_generator(text, voice):\n",
    "    return BrainBoxTaskPack(\n",
    "        BrainBoxTask(\n",
    "            id = BrainBoxTask.safe_id(), \n",
    "            decider='OpenTTS', \n",
    "            arguments=dict(voice='coqui-tts:en_vctk', lang='en', speakerId=voice, text=text)\n",
    "            ),\n",
    "        (),\n",
    "        DownloadingPostprocessor(take_element_before_downloading=0, opener=FileIO.read_bytes)\n",
    "    )\n",
    "\n",
    "template = Template(\n",
    "    'Set the timer for {hours} {hours_word} and {minutes} {minutes_word}',\n",
    "    hours = CardinalDub(0, 24),\n",
    "    hours_word = PluralAgreement('hours', 'hour', 'hours'),\n",
    "    minutes = CardinalDub(0, 60),\n",
    "    minutes_word = PluralAgreement('minutes', 'minute', 'minutes')\n",
    ").with_name('set_the_timer')\n",
    "\n",
    "with BrainBox().create_test_api() as bb_api:\n",
    "    service = BrainBoxDubbingService(task_generator, bb_api)\n",
    "    utterance = template.utter(dict(hours=11, minutes=1))\n",
    "    voiceover = service.dub_string(utterance.to_str(), 'p225').data\n",
    "Audio(value=voiceover, autoplay = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966a931-6a66-49ee-a58e-bed4db7af185",
   "metadata": {},
   "source": [
    "Run these cells to train Rhasspy on the template of the utterance (currently only one) and recognize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7c2e92b-dc2a-4360-98b4-b0348732eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_the_timer {'minutes': 1, 'hours': 11}\n"
     ]
    }
   ],
   "source": [
    "rhasspy_api = RhasspyAPI(ADDRESS, [template])\n",
    "rhasspy_api.train()\n",
    "recognized_utterance = rhasspy_api.recognize(voiceover)\n",
    "print(recognized_utterance.template.name, recognized_utterance.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2307d-8f4f-437c-a62b-217704b47341",
   "metadata": {},
   "source": [
    "So, it recognizes the file correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb4b4d-b41e-4a3b-ad76-8a458ff8a546",
   "metadata": {},
   "source": [
    "Then, we can use the test on the larger scale. \n",
    "First, we use predefined `Intents` that contain various intents.\n",
    "Second, we use TestingTools to generate lots of variants for the template with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5189b44b-2a47-48e2-9f27-c1a9c62cce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>true_intent</th>\n",
       "      <th>true_value</th>\n",
       "      <th>recognition_obj</th>\n",
       "      <th>parsed_intent</th>\n",
       "      <th>parsed_value</th>\n",
       "      <th>failure</th>\n",
       "      <th>match_intent</th>\n",
       "      <th>match_keys</th>\n",
       "      <th>match_values</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.yes</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sure</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.yes</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go on</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.yes</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No.</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.no</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop!</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.no</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       s                                  true_intent true_value  \\\n",
       "0    Yes  kaia.avatar.dub.sandbox.intents.Intents.yes         {}   \n",
       "1   Sure  kaia.avatar.dub.sandbox.intents.Intents.yes         {}   \n",
       "2  Go on  kaia.avatar.dub.sandbox.intents.Intents.yes         {}   \n",
       "3    No.   kaia.avatar.dub.sandbox.intents.Intents.no         {}   \n",
       "4  Stop!   kaia.avatar.dub.sandbox.intents.Intents.no         {}   \n",
       "\n",
       "  recognition_obj parsed_intent parsed_value  failure  match_intent  \\\n",
       "0            None          None         null    False         False   \n",
       "1            None          None         null    False         False   \n",
       "2            None          None         null    False         False   \n",
       "3            None          None         null    False         False   \n",
       "4            None          None         null    False         False   \n",
       "\n",
       "   match_keys  match_values  match  \n",
       "0       False         False  False  \n",
       "1       False         False  False  \n",
       "2       False         False  False  \n",
       "3       False         False  False  \n",
       "4       False         False  False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from kaia.avatar.dub.sandbox import Intents\n",
    "from kaia.avatar.dub.languages.en import TestingTools\n",
    "import pandas as pd\n",
    "from kaia.infra import FileIO\n",
    "from pathlib import Path\n",
    "\n",
    "tmp_folder = Path('rhasspy_test_files')\n",
    "os.makedirs(tmp_folder, exist_ok=True)\n",
    "samples_path = tmp_folder/'samples.pkl'\n",
    "\n",
    "if not samples_path.is_file():\n",
    "    test = TestingTools(Intents.get_templates(), 100)\n",
    "    FileIO.write_pickle(test, samples_path)\n",
    "else:\n",
    "    test = FileIO.read_pickle(samples_path)\n",
    "    \n",
    "TestingTools.samples_to_df(test.samples).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64544adf-1bf9-4cda-846f-84540cc1a925",
   "metadata": {},
   "source": [
    "We now need to build voice overs for all of these utterances. Here, a MediaLibrary will be very handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b51583c-bdd3-48e1-89e6-4361e99415db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "media_library_path = Path(tmp_folder/'rhasspy_test_voiceover.zip')\n",
    "\n",
    "def create_voiceover_task(samples):\n",
    "    tasks = []\n",
    "    tags = {}\n",
    "    dependencies = {}\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        id = BrainBoxTask.safe_id()\n",
    "        tasks.append(BrainBoxTask(id=id, decider='OpenTTS', arguments=dict(text=sample.s, voice='coqui-tts:en_vctk', lang='en', speakerId='p225')))\n",
    "        dependencies[id] = id\n",
    "        tags[id] = dict(sample_id=i, s=sample.s)\n",
    "    \n",
    "    voiceover_task = BrainBoxTask(id = BrainBoxTask.safe_id(), decider='Collector', arguments=dict(tags=tags), dependencies=dependencies)\n",
    "    return BrainBoxTaskPack(voiceover_task, tasks, DownloadingPostprocessor())\n",
    "\n",
    "\n",
    "if not media_library_path.is_file():\n",
    "    with BrainBox().create_test_api() as api:\n",
    "        task = create_voiceover_task(test.samples)\n",
    "        path = api.execute(task)\n",
    "        shutil.copy(path, media_library_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a335886-4c52-40be-9955-359f8ae3f8ad",
   "metadata": {},
   "source": [
    "Let's browse what's media library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b75fbcc-d8dd-4b9b-a08c-acecb579328a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>s</th>\n",
       "      <th>option_index</th>\n",
       "      <th>filename</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>a4bfe29d-2faf-4ed8-bb64-c90e3f906604.wav</td>\n",
       "      <td>2024-02-17 11:55:41.345600</td>\n",
       "      <td>id_121e1ead144c468bb68b462d53d6a944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sure</td>\n",
       "      <td>0</td>\n",
       "      <td>13bc1108-39ae-4042-a50f-1727df84bad4.wav</td>\n",
       "      <td>2024-02-17 11:55:41.345600</td>\n",
       "      <td>id_ca1f6e7eb6074ee382e310c53c528c39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Go on</td>\n",
       "      <td>0</td>\n",
       "      <td>3d2b913c-641c-4d82-ba47-dee0a4f35308.wav</td>\n",
       "      <td>2024-02-17 11:55:41.345600</td>\n",
       "      <td>id_c42570dc11da4ee5b826eb442902b65b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>No.</td>\n",
       "      <td>0</td>\n",
       "      <td>5ab0dac1-f321-43fd-81e9-89405146eeed.wav</td>\n",
       "      <td>2024-02-17 11:55:41.345600</td>\n",
       "      <td>id_a50c86288cad4df78f6f083352a22847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Stop!</td>\n",
       "      <td>0</td>\n",
       "      <td>3246a745-15fb-4aa4-be42-06eb270acc4b.wav</td>\n",
       "      <td>2024-02-17 11:55:41.345600</td>\n",
       "      <td>id_acbe52ac7d014688a24f7ccebe91398a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id      s  option_index                                  filename  \\\n",
       "0          0    Yes             0  a4bfe29d-2faf-4ed8-bb64-c90e3f906604.wav   \n",
       "1          1   Sure             0  13bc1108-39ae-4042-a50f-1727df84bad4.wav   \n",
       "2          2  Go on             0  3d2b913c-641c-4d82-ba47-dee0a4f35308.wav   \n",
       "3          3    No.             0  5ab0dac1-f321-43fd-81e9-89405146eeed.wav   \n",
       "4          4  Stop!             0  3246a745-15fb-4aa4-be42-06eb270acc4b.wav   \n",
       "\n",
       "                   timestamp                               job_id  \n",
       "0 2024-02-17 11:55:41.345600  id_121e1ead144c468bb68b462d53d6a944  \n",
       "1 2024-02-17 11:55:41.345600  id_ca1f6e7eb6074ee382e310c53c528c39  \n",
       "2 2024-02-17 11:55:41.345600  id_c42570dc11da4ee5b826eb442902b65b  \n",
       "3 2024-02-17 11:55:41.345600  id_a50c86288cad4df78f6f083352a22847  \n",
       "4 2024-02-17 11:55:41.345600  id_acbe52ac7d014688a24f7ccebe91398a  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaia.brainbox import MediaLibrary\n",
    "\n",
    "lib = MediaLibrary.read(media_library_path)\n",
    "lib.to_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4453836-e123-4647-ae9a-df2f96b682ba",
   "metadata": {},
   "source": [
    "Now, we will feed all the sound files from media library to RhasspyAPI and recognize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8faab1f-a92e-4cf6-b3fd-039424aa6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_path = tmp_folder/'test_results.pkl'\n",
    "\n",
    "if not test_result_path.is_file():\n",
    "    lib = MediaLibrary.read(media_library_path)\n",
    "    sample_index_to_file = {record.tags['sample_id'] : record for record in lib.records}\n",
    "    rhasspy_api = RhasspyAPI(ADDRESS, test.intents)\n",
    "    rhasspy_api.train()\n",
    "    test_result = test.test_voice(sample_index_to_file, rhasspy_api)\n",
    "    FileIO.write_pickle(test_result, test_result_path)\n",
    "else:\n",
    "    test_result = FileIO.read_pickle(test_result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756e6fd-c064-4c5a-8c96-026ecc3823d2",
   "metadata": {},
   "source": [
    "Let's see some stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46786bd9-e898-47a3-8914-011d793c8c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9935483870967742, 0.7806451612903226)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test.samples_to_df(test_result)\n",
    "df.match_intent.mean(), df.match_values.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972f9bbf-056a-49be-bc2e-e47fc4b9953c",
   "metadata": {},
   "source": [
    "## Notes on Rhasspy/TTS test\n",
    "\n",
    "Using Rhasspy to test TTS is a perfect way to see flaws in the TTS solution. This was the way how we realized that using TortoiseTTS to produce fragments and then combine these fragmets is not really a viable option. Moreover, we discovered some fixable issues as well:\n",
    "\n",
    "* the upper bounds of string to voiceover with Tortoise: around 60-70 characters. Sometimes, much longer strings can be processed, but sometimes no.\n",
    "\n",
    "* that sequences like \"six, sixteenth, sixth, sixtieth, sixty, tenth\" are not the best way to organize the voiceover, as TortoiseTTS fails to pronounce \"tenth\" in this case.\n",
    "\n",
    "* How to cut sequence like \"three, four\" into fragments. It appears the correct cut is \"three, \" and \"four\". \"three\"/\"four\" will lose the ending of \"three\", and \"three,\"/\" four\" will add a noise to the beginning of \"four\". Unfortunately, there is no pause tag in TortoiseTTS that could improve this even further.\n",
    "\n",
    "Moreover, used such analysis to understand, which fragments need to be re-generated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
